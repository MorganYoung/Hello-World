
##压力测试的现象和优化过程

###1. 初始软硬件和网络环境

* 3台ECS
* 双核，4G内存，250G硬盘
* 公网带宽10M
* 操作系统 CentOS6.4 X64
* 通过VPN接入ECS内网，办公场所20M带宽，多人共享（上行500K下行2M左右）
* 一台RDS（双核，6G内存，500G硬盘，IOPS 6000，与ECS内网相连）

###2. Application环境

* Apache Tomcat 7 * 2台
* JDK1.7u55（HotSpot）X86、X64
* Weblogic10.3.4
* Tengine1.x
* APR1.5.0
* Tomcat需要配置好JMX环境
* 程序代码

###3. 测试工具和环境

* Jmetter 2.11
* Visual VM
* Jconsole
* Loadrunner
* SSH
* 本地网络流量监控软件（360，金山）
* 本地局域网络监控（路由器自带）

###3. 压测现象和环境优化
*** 

#### 3.1Jmatter压测

最初采用Jmetter录制的投保流程进行测试并发数为100；模拟100个用户不断重复投保流程。

> 脚本的很多步骤都有（500）错误，整体错误率在20%左右;

> 吞吐率大概在4000 response/min左右;

> 网络流量在270KB/S左右，没有达到本地出口（20M带宽）的上限。

> ECS上的tomcat进程（java）CPU利用率在85%以上

后来调整到50并发后上面的问题依旧存在，没有任何改善，只是吞吐率更低了。

最后直到降低到1个并发的时候问题依旧存在。

再看服务器端，有大量的 OutOfMemory 错误。

此时的tomcat配置为。

#####server.xml

	
	<Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
        maxThreads="1000" minSpareThreads="300" />
	<!-- 线程池 -->
	<Connector port="8787"
        URIEncoding="UTF-8"
        connectionTimeout="20000"
        executor="tomcatThreadPool"
        protocol="HTTP/1.1"
        enableLookups="false"
        acceptCount="1000"
        redirectPort="8443" />

#####context.xml 数据源配置

	
   	<Resource name="EpiccDataSource" auth="Container" type="javax.sql.DataSource"
    	url="***"
       	driverClassName="com.mysql.jdbc.Driver"
        password="***" username="***"
       	maxActive="20"
        maxIdle="10"
        />
	还有三个数据源，但配置都是一样的


#####catalina.sh JVM内存配置

此时使用的是32位的JDK

	JAVA_OPTS="-server -Xms1024m -Xmx1024m -Xss512K -XX:PermSize=64m -XX:MaxPermSize=128m "
	
为了更进一步的分析问题产生的原因，我们启用了JDK的HeapDumpOnOutOfMemoryError。

#####更改后的 catalina.sh

	JAVA_OPTS="-server -Xms1024m -Xmx1024m -Xss512K -XX:PermSize=64m -XX:MaxPermSize=128m
	 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/tomcat/ "

随后又进行了一次20并发的压测，果然在/opt/tomcat目录下产生了一个800M左右的hprof文件。

借助Jprofiler和VisualVM发现了问题的所在:

Jprofiler分析整个堆的内存占用发现org.apache.lucene.store.RAMFile这个类型占用了95%的空间
> field {buffers:bold} of org.apache.lucene.store.RAMFile	670295600（670M）	644515（Object Count）

借助Visual VM查看当时的错误堆栈信息(导致ava.lang.OutOfMemoryError的线程)，发现在最后保存的时候由于业务需要利用lucene进行全文索引查找，索引的内容是数据库中的几张大表；每次查找都会实例化一个RAMFile对象，这样导致的大量的内存被占用，索引文件大小在不断增长。

	Directory dir = null;
		try {
		    String indexLocation = EbsConfig.getProperty("Area10000000", "Pub", "Proposal", "indexLocation");
		    File indexDir = new File(InitEbsConfig.configPathxd+indexLocation);
		    dir = new RAMDirectory(FSDirectory.open(indexDir));
		} catch (IOException e1) {
			e1.printStackTrace();
		} catch (Exception e) {
			e.printStackTrace();
		}
		return dir;

我们将索引的加载其改为了单例的RAMDirectory模式，并在初始化静态实例时加上了锁。

	public class DirectoryHelper {

	private static Directory directory = null;
	
	public static Directory getInstance() {
		try {
			String indexLocation = EbsConfig.getProperty("Area10000000", "Pub", "Proposal", "indexLocation");
			File indexDir = new File(InitEbsConfig.configPathxd+indexLocation); 
			if(directory == null) {
				Lock lock = null;
				try{
					lock = new ReentrantLock();
					lock.lock();
					directory = new RAMDirectory(FSDirectory.open(indexDir));
				} finally {
					if(lock != null) {
						lock.unlock();
					}
				}
			}
		} catch (IOException e1) {
			e1.printStackTrace();
		} catch (Exception e) {
			e.printStackTrace();
		}
		return directory;
	}
	}

同时我们也将JVM的内存增大到1.5G
	
> JAVA_OPTS="-server -Xms1500m -Xmx1500m -Xss512K -XX:PermSize=128m -XX:MaxPermSize=256m "

这次应该不会有问题了吧，我们再次用20并发进行的测试。结果问题依旧出现了，又出现了OutOfMemory的错误，并且产生了新的hprof文件。

错误信息：

> java.lang.OutOfMemoryError.<init>(OutOfMemoryError.java:48)

> ...	at ......DirectoryHelper.getInstance(DirectoryHelper.java:32)

下面分析一下问题吧：

我们在代码中这样写道：
> directory = new RAMDirectory(FSDirectory.open(indexDir));

我们new了一个RAMDirectory作为一个唯一的静态实例，存储在DirectoryHelper类里面，但是我们忽略了主要的一点，就是即便我们把Directory单利化了，但是Directory里面的索引等数据还是会在查找的时候全部加载到内存，等到查找完成后才进行内存的释放（等到下一个GC来临的时候）；这样的话如果是在并发查找的情况下还是会产生多个RAMIndex实例，1.5G的堆内存，很快就会被消耗殆尽。

现在我们明白了问题依旧出现的原因所以我们决定不采用RAMDirectory，而是直接返回一个Directory。

修改过后的 DirectoryHelper代码：

	public class DirectoryHelper {

	private static Directory directory = null;

	public static Directory getInstance() {
    try {
        ...//同上
                directory = FSDirectory.open(indexDir);
        ...
    return directory;
	}
	}

但是这样做的代价是可能会降低索引查找的效率，因为索引文件不再装载到内存中，而是直接在文件中查找。

*** 

####3.2. 对带宽的质疑

由于我们测试是基于VPN连接的，所以我们的带宽会受到工作所在地点的带宽影响（用的是电信的20M（20Mbps bit per second）宽带），在测试之前就一直怀着这样一个疑问：20M的带宽如何进行压力测试。（肯定会在带宽上受到较大的影响啊，最大下行也就是 2.5M/s ）但是我们没有经过仔细的计算，下面我们计算一下，到底在20M的带宽下能进行多大规模的压测。

#####1. 最大上下行带宽的计算。 

办公地点的带宽是电信20M宽带即：
> 20 * 1024 * 1024 = 20971520 bps

那最大下行应该是多大呢 ：
> 1Byte = 8bit

> 20 * 1024 * 1024 bps / 8 = 2621440 Bps = 2560 KBps = 2.5 MBps (每秒2.5M字节下载)

那最大上行应该多大呢：理论上和下行应该一样大小，但是电信把我们的限制在了1Mbps

> 1 * 1024 * 1024 bps / 8 = 131072 Bps = 128 KBps(每秒128K字节上传)

#####2. 每秒能够处理传输的请求

那我们理论上最大能够每秒处理多少个请求呢？

经过统计一个正确的流程需要300个request 传输数据 951.5KB，包括首页，如果不包括首页的话是245个request 传输数据650KB

平均每个请求消耗下行带宽（上行忽略）
> 951.5 / 300 = 3.17KB

那么按照2.5MBps的传输速率计算，每秒能够处理的请求数是：

> 2.5 * 1024 KB / 3.17 KB = 807.6

但考虑到实际情况，我们的带宽不会达到100%的连接率，由于网络原因，多人办公的原因等等。所以最好的带宽预估是80%的带宽给测试使用，也就是2MKB/s的传输率,那每秒处理的请求数是：
>2 * 1024 KB / 3.17 KB = 646

#####3. 对测试结果的预估（理想状况下）

一个流程总共需要300个request，所以带宽上每秒能够处理的流程是：
> 646 / 300 = 2.15

好了，经过我们的计算得到了一个每秒2.15个流程的预估值（这也是在比较理想的情况下）

就看我们的测试结果了。。。

*** 
####3.3 Jmeter的远程测试
起初我们认为如果能够在远程的服务器上启动jmeter来进行测试的话，就可以忽略网络因素的限制了，因为几台ECS是在一个内网下的。

但后来我们才发现，这种基于远程测试的jmeter方案，并不能够得到我们想要的测试结果。第一，在ECS上的jmeter是基于命令行的方式启动的，只有一个测试结果的记录，远远没有jmeter GUI 的方式能够拿到的测试数据和分析数据多。第二，如果想要得到丰富的GUI的测试结果记录，那必须采用远程启动Jmeter的方式；jmeter测试数据的回传上同样受到了本地带宽的影响。但不管怎么说jmeter的远程测试是他的一大优点，下面记录一下如何配置jmeter的远程测试：

到apache Jmeter官网上下载好jmeter后（我们用的是2.11版本），配置bin/jmeter.properties文件

##### 客户端的 jmeter.properties

	找到这一行
	# Remote Hosts - comma delimited
	remote_hosts=127.0.0.1,*.*.*.* 
	# 将*.*替换成服务器的地址，或者采用下面的方式加上:port
	#remote_hosts=localhost:1099,localhost:1099

然后我们双击打开jmeter.bat 在 【运行】->【远程启动】就能够看见添加好的远程jmeter服务端

#####服务端的 jmeter.properties

	# RMI port to be used by the server (must start rmiregistry with same port)
	# server_port=1099 //这个是jmx注册的端口
	# To use a specific port for the JMeter server engine, define
	# the following property before starting the server:
	# server.rmi.localport=4000 //这个才是JMX传输数据用的端口

#####服务端的 jmeter-server.sh

	# One way to fix this is to define RMI_HOST_DEF below

	#RMI_HOST_DEF=-	Djava.rmi.server.hostname=xxx.xxx.xxx.xxx
	#将客户端的远程地址，也就是服务端的外网地址写在这上面

如果有防火墙的话一定要把两个端口都打开一个是1099，一个是4000

在服务端启动 jmeter-server就会出现如下信息

	Created remote object: UnicastServerRef [liveRef: [endpoint:[xxx.xxx.xxx.xxx:4000]
	(local),objID:[-3802d6b2:1458261e0b3:-7fff, 8905503415908405556]]]

然后在jmeter客户端远程启动一个编辑好的计划就可以了。。。

这是一个小插曲，下面才是我们真正的测试。。。

*** 

#### Loadrunner压测

我们和一位专业的测试人员在一起进行了针对投保流程在Loadrunner上的压测。

最初我们采用20用户的并发（压测单台tomcat），每次持续20分钟的时间。

为了能够监控到JVM的情况，我们在tomcat上面启用了JMX，并在本地采用Jconsole进行监控，同时我们也增大了JVM的内存配置。

##### JVM 和 JMX配置

	JAVA_OPTS="-server -Xms2000m -Xmx2000m -Xss512K -XX:PermSize=128m -XX:MaxPermSize=512m 
	-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/tomcat/ "
 
	JAVA_OPTS="$JAVA_OPTS -Djava.rmi.server.hostname=*.*.*.* 
	-Dcom.sun.management.jmxremote.ssl=false 
	-Dcom.sun.management.jmxremote.authenticate=false"

我们利用tomcat的JmxRemoteLifecycleListener进行JMX的端口配置（由于防火墙的存在）
##### JMX server.xml配置

	<Server port="8005" shutdown="SHUTDOWN">
        <Listener className="org.apache.catalina.mbeans.JmxRemoteLifecycleListener"
                  rmiRegistryPortPlatform="1099" rmiServerPortPlatform="10990" />

下面给出一个比较完整的 tomcat JMX配置方案（摘自博客）

#####使用JMX透过防火墙远程监控tomcat服务

JDK的bin目录下有jvisualvm或jconsole可以监控本地和远程jvm实例的运行动态（包括cpu，内存等）， 对于性能分析或内存泄露分析等极其方便。下面介绍如何通过这两个工具远程监控有防火墙的linux上的tomcat服务。

我的测试环境是：centos 6.2（IP为192.168.1.118）上通过jsvc将tomcat 7作为服务启动。

下载http://mirror.bjtu.edu.cn/apache/tomcat/tomcat-7/v7.0.28/bin/extras/catalina-jmx-remote.jar并放在tomcat7的$CATALINA_BASE/lib目录。

修改tomcat7的$CATALINA_BASE/conf/server.xml,在 下加入监听器：

	<Listener className="org.apache.catalina.mbeans.JmxRemoteLifecycleListener"
 	 rmiRegistryPortPlatform="10001" rmiServerPortPlatform="10002" />
建立文本文件$CATALINA_BASE/conf/jmxremote.password，其内容为：admin letmein

建立文本文件$CATALINA_BASE/conf/jmxremote.access，其内容为：admin readwrite

修改jsvc的服务启动配置文件，加入启动参数，如：

	CATALINA_OPTS="$CATALINA_OPTS -Xms128m -Xmx200m -XX:PermSize=64M -XX:MaxPermSize=256m -XX:+UseConcMarkSweepGC \
	-Djava.rmi.server.hostname=192.168.1.118 \
	-Dcom.sun.management.jmxremote.password.file=$CATALINA_BASE/conf/jmxremote.password \
	-Dcom.sun.management.jmxremote.access.file=$CATALINA_BASE/conf/jmxremote.access \
	-Dcom.sun.management.jmxremote.ssl=false"
开通linux防火墙的端口：10001和10002.（例如：在/etc/sysconfig/iptables中加入）

	-A INPUT -m state --state NEW -m tcp -p tcp --dport 10001 -j ACCEPT
	-A INPUT -m state --state NEW -m tcp -p tcp --dport 10002 -j ACCEPT），

注意要重启防火墙使生效。

至此远程可以使用jvisualvm或jconsole通过地址：（192.168.1.118:10001或者service:jmx:rmi:///jndi/rmi://192.168.1.118:10001/jmxrmi）,使用用户admin密码letmein登录 动态监控tomcat服务了。

#####Loadrunner压测时产生的状况

在实际压测的时候，发现网络的占用情况还不到40%，其中有几个步骤比较慢，一个请求40多秒；但系统勉强撑得过去。

然后我们加到30并发的时候问题产生了，出现了严重的超时情况，但查看服务端的日志信息，没有出现error，除了大量的输出信息（Sysytem.out）

我们已经将JVM内存调整到2G了，这基本上市32位JVM的极限了，随然没有出现内存溢出的情况，但如此高的延时，让我们难以接受。

#####慢 SQL

我们在数据库端发现了问题，有一条查询的SQL的执行时间要十几秒，而那条SQL就是一个简单的嵌套查询，使用了in，并且in里面的查询是一个数量在7000左右的表查询；我们将这条语句放到数据库执行了一下，果真执行了17秒多。

为什么会如此慢？？

在讲这条SQL为什么慢之前我们先介绍一下

#####Mysql 慢查询

慢查询有什么用? 它能记录下所有执行超过long_query_time时间的SQL语句, 帮你找到执行慢的SQL, 方便我们对这些SQL进行优化；如何开启慢查询? 首先我们先查看MYSQL服务器的慢查询状态是否开启. 执行如下命令: 

**方式一，通过命令**

	mysql> show variables like "%long%";         //查看一下默认为慢查询的时间10秒  
	+-----------------+-----------+  
	| Variable_name   | Value     |  
	+-----------------+-----------+  
	| long_query_time | 10.000000 |  
	+-----------------+-----------+  
	1 row in set (0.00 sec)  
  
	mysql> set global long_query_time=2;          //设置成2秒，加上global,下次进mysql已然生效  
	Query OK, 0 rows affected (0.00 sec)  
  
	mysql> show variables like "%slow%";          //查看一下慢查询是不是已经开启  
	+---------------------+---------------------------------+  
	| Variable_name       | Value                           |  
	+---------------------+---------------------------------+  
	| log_slow_queries    | OFF                             |  
	| slow_launch_time    | 2                               |  
	| slow_query_log      | OFF                             |  
	| slow_query_log_file | /usr/local/mysql/mysql-slow.log |  
	+---------------------+---------------------------------+  
	4 rows in set (0.00 sec)  
	  
	mysql> set slow_query_log='ON';                        //加上global，不然会报错的。  
	ERROR 1229 (HY000): Variable 'slow_query_log' is a GLOBAL
	 variable and should be set with SET GLOBAL  
	mysql> set global slow_query_log='ON';            //启用慢查询  
	Query OK, 0 rows affected (0.28 sec)  
  
	mysql> show variables like "%slow%";              //查看是否已经开启  
	+---------------------+---------------------------------+  
	| Variable_name       | Value                           |  
	+---------------------+---------------------------------+  
	| log_slow_queries    | ON                              |  
	| slow_launch_time    | 2                               |  
	| slow_query_log      | ON                              |  
	| slow_query_log_file | /usr/local/mysql/mysql-slow.log |  
	+---------------------+---------------------------------+  
	4 rows in set (0.00 sec)  

**方式二，通过修改my.cnf配置文件（window是my.ini）**

在[mysqld]里面加上以下内容

	long_query_time = 2  
	log-slow-queries = /usr/local/mysql/mysql-slow.log  

我们已经开启了mysql的慢查询日志功能，并且设定了慢查询的界限是2秒，那如何分析慢查询的sql呢？

#####Mysql慢查询分析工具
分析工具干什么事的呢，其实就是把mysql-slow.log里面记录下来的数据，分析一下显示出来。其实自己写一个shell脚本也是可以把要的信息取出来的。我们来看一下mysql-slow.log里面到底是什么东西

	[root@BlackGhost mysql]# cat mysql-slow.log     //查看命令  
	/usr/local/mysql/libexec/mysqld, Version: 5.1.26-rc-log (Source distribution). started with:  
	Tcp port: 3306  Unix socket: /tmp/mysql.sock  
	Time                 Id Command    Argument  
	# Time: 100814 13:28:30  
	# User@Host: root[root] @ localhost []  
	# Query_time: 10.096500  Lock_time: 0.045791 Rows_sent: 1  Rows_examined: 2374192  
	SET timestamp=1281763710;  
	select count(distinct ad_code) as x from ad_visit_history where ad_code in (select ad_code from ad_list where media_id=15);  
	# Time: 100814 13:37:02  
	# User@Host: root[root] @ localhost []  
	# Query_time: 10.394134  Lock_time: 0.000091 Rows_sent: 1  Rows_examined: 2374192  
	SET timestamp=1281764222;  
	select count(distinct ad_code) as x from ad_visit_history where ad_code in (select ad_code from ad_list where media_id=15);  
	# Time: 100814 13:37:16  
	# User@Host: root[root] @ localhost []  
	# Query_time: 4.608920  Lock_time: 0.000078 Rows_sent: 1  Rows_examined: 1260544  
	SET timestamp=1281764236;  
	select count(*) as cou  from ad_visit_history where ad_code in (select ad_code from ad_list where id=41) order by id desc; 

看到了，就是记录一下sql语句的执行情况，包括执行时间，锁定时间等，所以要不要分析工具看个人情况，分析工具很多，在这儿只说一下mysql自带的慢查询分析工具
**mysqldumpslow**
的使用方法。

	# mysqldumpslow --help  

	Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]  
  
	Parse and summarize the MySQL slow query log. Options are  
  
 	--verbose    verbose  
 	--debug      debug  
 	--help       write this text to standard output  
  
 	-v           verbose  
 	-d           debug          //查错  
 	-s ORDER     what to sort by (t, at, l, al, r, ar etc), 'at' is default     
	//排序方式query次数，时间，lock的时间和返回的记录数来排序  
 	-r 	          reverse the sort order (largest last instead of first)       //倒排序  
 	-t NUM       just show the top n queries                                       //显示前N多个  
 	-a           don't abstract all numbers to N and strings to 'S' 
 	-n NUM       abstract numbers with at least n digits within names   //抽象的数字，至 少有n位内的名称 
	-g PATTERN   grep: only consider stmts that include this string      //配置模式 
  	-h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),     // mysql所以机器名或者IP 
	default is '*', i.e. match all 
 	-i NAME      name of server instance (if using mysql.server startup script) 
 	-l           don't subtract lock time from total time           //总时间中不减去锁定时间  

**例如**

	[root@... bin]# ./mysqldumpslow -s r -t 20 /usr/local/mysql/mysql-slow.log
	[root@... bin]# ./mysqldumpslow -s r -t 20 -g 'count' /usr/local/mysql/mysql-slow.log

关于慢查询的配置摘自[这篇博客](http://blog.51yip.com/mysql/972.html)

好了，我们已经能够找到了这些慢查询，那么如何让他们不再慢。造成慢查询的情况会有很多，下面大致罗列一下导致出现慢查询的原因。

	1. 没有索引或没有用到索引。
	2. IO吞吐量小形成了瓶颈。
	3. 内存不足。
	4. 网络速度慢。
	5. 一次查询的数据量过大。
	5. 出现死锁。
	6. 返回了不必要的行或列。
	7. 注意UNion和UNion all 的区别。（UNION all好）
经过查证我们发现了问题正是由于第一条原因引起的，没有索引。

**Mysql索引**

索引用来快速地寻找那些具有特定值的记录，所有MySQL索引都以B-树的形式保存。如果没有索引，执行查询时MySQL必须从第一个记录开始扫描整个表 的所有记录，直至找到符合要求的记录。表里面的记录数量越多，这个操作的代价就越高。如果作为搜索条件的列上已经创建了索引，MySQL无需扫描任何记录 即可迅速得到目标记录所在的位置。如果表有1000个记录，通过索引查找记录至少要比顺序扫描记录快100倍。

**索引类型：**

> 普通索引：这是最基本的索引类型，没唯一性之类的限制。

> 唯一性索引：和普通索引基本相同，但所有的索引列只能出现一次，保持唯一性。

> 主键：主键是一种唯一索引，但必须指定为"PRIMARY KEY"。

> 全文索引：MYSQL从3.23.23开始支持全文索引和全文检索。在MYSQL中，全文索引的索引类型为FULLTEXT。全文索引可以在VARCHAR或者TEXT类型的列上创建。

关于mysql索引参考了[这篇博文](http://blog.chinaunix.net/uid-25525723-id-171236.html)

我们在查询的字段上建立了普通索引，然后我们再次执行了一下这条sql，100多毫秒，整整快了100多倍。

好了，我们可以继续增大并发数了。

由于之前我们已经在tomcat生面配置好了JMX；我们通过Jconsole jmx连接到测试服务器，来监控JVM的内存使用情况，发现当我们逐渐增加并发数时，堆内存的使用量一直居高不下；而且随着并发数的增加，堆内存的使用还是在不断的持续增长；再看看FullGC的时间间隔，大概在20分钟到30分钟左右（还算可以）。

其实作为一个运行在服务器上的Application来说2G的JVM堆内存分配确实有些寒酸。系统的内存是4G，应该能够分配给JVM一些，于是我们继续扩大了堆内存。

#####从32位JDK到64位JDK
我们想在2G的基础上在增大JVM内存，那就不得不考虑更换64位版本的JDK了。

于是我们更换的JDK，同时调整的JVM的GC策略。

#####JVM的GC调整

	JAVA_OPTS="-server -Xms2400m -Xmx2400m \
	-Xss512K -XX:PermSize=128m -XX:MaxPermSize=512m \
	-XX:+AggressiveOpts \
	-XX:+UseBiasedLocking \
	-XX:+DisableExplicitGC \
	-XX:MaxTenuringThreshold=31 \
	-XX:+UseConcMarkSweepGC \
	-XX:+UseParNewGC  \
	-XX:+CMSParallelRemarkEnabled \
	-XX:+UseCMSCompactAtFullCollection \
	-XX:LargePageSizeInBytes=128m \
	-XX:+UseFastAccessorMethods \
	-XX:+UseCMSInitiatingOccupancyOnly \
	-Djava.awt.headless=true \
	-XX:+HeapDumpOnOutOfMemoryError \
	-XX:HeapDumpPath=/opt/tomcat/ \
	-Djava.library.path=/usr/local/apr/lib" //APR的配置，后面会提到。

上面的一堆的-XX是什么呢？下面来讲一下：

#####tomcat性能优化
***
**一.tomcat优化方向**

要优化调整tomcat，首先要知道决定性能的几个重要指标

1. 吞吐量
2. Responsettime（响应时间）
3. Cpuload（cpu负载）
4. MemoryUsage(内存占用)

通过对tomcat的各种配置的调整，使其最优化上面4个核心指标的读数。解决了以下2点：

1. 承受更大并发用户数
2. 取得了良好的性能与改善

**二．tomcat优化步骤**

Tomcat的优化分成两块：

1. Tomcat启动命令行中的优化参数即JVM优化。
2. Tomcat容器自身参数的优化。

先要讲的是Tomcat启动命令行中的优化参数。
Tomcat首先跑在JVM之上的，因为它的启动其实也只是一个java命令行，首先我们需要对这个JAVA的启动命令行进行调优。

**三．Tomcat启动行参数的优化**

Tomcat的启动行参数位于tomcat安装目录的bin文件夹下。在windows中文catalina.bat 。文件在linux系统下为catalina.sh文件。打开该文件，开头一般都是一堆注释文字。在其末尾处加入如下参数
Linux系统的tomcat启动参数

见上面**JVM的GC调整**

有些参数需要根据机器情况来填写相应的值下面

参数说明：

	-server
	Tomcat运行在生产环境中必加的选项，以server模式运行

	-Xms –Xmx
	即JVM的内存设置，将两个值设置成一样是最优化配置。设置最大值时用命令 java –Xmx1500m–version 来试试限制。
	能正常显示版本信息则为正常

	-Xmn
	设置年轻代的大小整个堆大小=年轻代大小+年老代大小+持久代大小。持久代一般固定64M
	 所以增大年轻大后，会减少年老代大小，对系统性能影响较大，官方推荐为整个堆的3/8.

	-Xss
	设置每个线程的堆栈大小，一般不要超过1M，要不然容易内存溢出

	-XX :+AggressiveOpts
	    加入JDK动态升级，当JDK升级时tomcat也能获得最新技术的支持

	-XX :+UseBiasedLocking
	启用一个优化的线程锁，使得appserver对内线程处理自动进行最优调配

	-XX :PermSize=128M –XX:MaxPermSize=256M
	Permsize设置非堆内存初始值，一般为物理内存的1/64
	MaxPermSize设置最大非堆内存值，一般为物理内存的1/4
	在数据量很大的文件导出时的必设项，否则可能导致内存溢出

	-XX:+DisableExpllicitGC
	在程序代码中不允许有显示的调用System.gc(),避免其导致的Full GC造成的JVM大起大落

	-XX:+UseParNewGC
	对年轻代采取多线程并行回收，加快回收速度

	-XX:+UseConcMarkSweepGC
	即CMS gc，这一特性只有jdk1.5即后续版本才具有的功能，它使用的是gc估算触发和heap占用触发。
	我们知道频频繁的GC会造面JVM的大起大落从而影响到系统的效率，因此使用了CMS GC后可以在
	GC次数增多的情况下，每次GC的响应时间却很短，

	-XX:MaxTenuringThreshold
	设置垃圾最大年龄，设置为0的话，则年轻代不经过Survivor区，直接变为年老代，设置较大的值的话，可以
	增加对象在年轻代即回收的概率。具体值根据实际来设置

	-XX:+CMSParallelRemarkEnabled
	在使用UseParNewGC的情况下尽量减少Mark时间

	-XX:+UseCMSCompactAtFullCollection
	在使用concurrent gc 的情况下, 防止memoryfragmention, 对live object 进行整理, 使 memory 碎片减少。

	-XX:+LargePageSizelnBytes=128m
	指定 Java heap的分页页面的大小

	-XX:+UseFastAccessorMethods
	Get， set 方法转成本地代码

	-XX:+UseCMSlnitiatingOccupancyOnly
	指示只有在oldgeneration在使用了初始化比例后concurrent collector启动收集

	-Djava.awt.headless=true
	这个参数一般我们都是放在最后使用的，这全参数的作用是这样的，有时我们会在我们的J2EE工程中使用一些
	图表工具如：jfreechart，用于在web网页输出GIF/JPG等流，在winodws环境下，一般我们的app server
	在输出图形时不会碰到什么问题，但是在linux/unix环境下经常会碰到一个exception导致你在winodws开
	发环境下图片显示的好好可是在linux/unix下却显示不出来，因此加上这个参数以免避这样的情况出现。

上述的配置基本可以达到

1. 系统响应时间增快
2. Jvm回收速度增快同时又不影响系统响应时间
3. Jvm内存最大化利用
4. 线程阻塞情况最小化

**四．Tomcat容器内的优化**

前面对Tomcat启动时的命令进行了优化增加了系统JVM的可使用数，垃圾回收效率与线程阻塞情况，增加了系统响应效率等。还有一个很重要的指标没有优化——吞吐量。

打开tomcat安装目录/conf/server.xml后找到如下一行
这一行就是tomcat容器性能参数设置的地方，一般会有一个默认值，这些默认值是远远不够我们使用的。因此需要做如下的修改

	<Connector port="8787"
        maxHttpHeaderSize="8192"
        useBodyEncodingForURI="true" 
        useURIValidationHack="false"
        noCompressionUserAgents="gozilla,traviata" 
        compression="on" compressionMinSize="2048"
        compressableMimeType="text/html,text/xml,text/javascript,text/css,text/plain"  
        disableUploadTimeout="true"
        URIEncoding="UTF-8"
        connectionTimeout="20000"
        protocol="org.apache.coyote.http11.Http11AprProtocol" 
        enableLookups="false"
        acceptCount="2000"
        redirectPort="8443"
        maxSpareThreads="1000" 
        maxThreads="1000" 
        minSpareThreads="300"
        maxProcessors="2000" 
        minProcessors="500" />

**注**：
在tomcat7以后,同时protocol用了apr，启动的时候会报如下警告
> Apr 18, 2014 3:25:28 PM org.apache.catalina.startup.SetAllPropertiesRule begin
WARNING: [SetAllPropertiesRule]{Server/Service/Connector} Setting property 'useURIValidationHack' to 'false' did not find a matching property.

> Apr 18, 2014 3:25:28 PM org.apache.catalina.startup.SetAllPropertiesRule begin
> WARNING: [SetAllPropertiesRule]{Server/Service/Connector} Setting property 'maxSpareThreads' to '1000' did not find a matching property.
> 
> Apr 18, 2014 3:25:28 PM org.apache.catalina.startup.SetAllPropertiesRule begin
WARNING: [SetAllPropertiesRule]{Server/Service/Connector} Setting property 'maxProcessors' to '2000' did not find a matching property.

> Apr 18, 2014 3:25:28 PM org.apache.catalina.startup.SetAllPropertiesRule begin
WARNING: [SetAllPropertiesRule]{Server/Service/Connector} Setting property 'minProcessors' to '500' did not find a matching property.

useURIValidationHack,maxSpareThreads,maxProcessors,minProcessors着四个属性在启用apr后会失效。（说完了这一节我们会讲APR）

参数说明

	URIEncoding=“UTF-8”
	使得tomcat可以解析含有中文名的文件的url

	maxSpareThreads=“75”
	空闲状态的线程数多于设置的数目，则将这些线程终止，减少这个池中的线程总数

	minSpareThreads=”25”
	最小备用线程数。Tomcat启动时的初始线程数。

	EnableLookups=false
	DNS寻找，设为关闭。

	ConnectionTimeout=20000
	为网络连接超时时间毫秒数

	acceptCount=300
	是当线程数达到maxThreads后，后续请求会被放入一个等待队列，这里设置的就是队列大小，
	如果这个也满了，就直接拒绝连接。

	maxthreads=300
	tomcat使用线程来处理接收数据的最大线程，即最大并发数。

	maxProcessors=1000和mincessors=5
	在 Java中线程是程序运行时的路径，是在一个程序中与其它控制线程无关的、能够独立运行的代码段。
	它们共享相同的地址空间。多线程帮助程序员写出CPU最 大利用率的高效程序，使空闲时间保持最低，
	从而接受更多的请求。通常Windows是1000个左右，Linux是2000个左右。

	useURIValidationHack=false
	可以减少对url的一些不必要的检查以减少开销。

	给tomcat配置http压缩功能
	HTTP 压缩可以大大提高浏览网站的速度，它的原理是，在客户端请求网页后，从服务器端将网页文件压缩，
	再下载到客户端，由客户端的浏览器负责解压缩并浏览。相对于普通的浏览过程HTML,CSS,Javascript, 
	Text ，它可以节省40%左右的流量。更为重要的是，它可以对动态生成的，包括CGI、PHP , JSP ,
	 ASP , Servlet,SHTML等输出的网页也能进行压缩，压缩效率惊人。

	1. compression="on"打开压缩功能
	2. compressionMinSize="2048"启用压缩的输出内容大小，这里面默认为2KB
	3. noCompressionUserAgents="gozilla,traviata" 对于以下的浏览器，不启用压缩
	4. compressableMimeType="text/html,text/xml"　压缩类型

#####Tomcat的APR
***
APR是什么有什么作用，我们来看看，Apache Tocmat官网对APR的描述[原文地址](http://tomcat.apache.org/tomcat-7.0-doc/apr.html)

> Tomcat can use the Apache Portable Runtime to provide superior scalability, performance, and better integration with native server technologies. The Apache Portable Runtime is a highly portable library that is at the heart of Apache HTTP Server 2.x. APR has many uses, including access to advanced IO functionality (such as sendfile, epoll and OpenSSL), OS level functionality (random number generation, system status, etc), and native process handling (shared memory, NT pipes and Unix sockets).

> These features allows making Tomcat a general purpose webserver, will enable much better integration with other native web technologies, and overall make Java much more viable as a full fledged webserver platform rather than simply a backend focused technology.

大概意思是：（借助Google 翻译了一下。呵呵。）

Tomcat可以使用APR提供卓越的可扩展性、性能、以及与本地服务器技术更好的融合。APR是一个高度可移植的库，它是Apache HTTP2.x的核心。APR有很多用途，包括访问高级的IO功能，操作系统级别的功能（随机数生成，系统状态等），以及本地进程处理（共享内存，NT管道和Unix Socket）

这些特性使Tomcat成为了一个通用的webserver，能够与其他本地网络技术更好的整合，使整个JAVA就像一个完整成熟的的webserver平台，而不是一个简单的后台集中技术。

听起来好像挺牛X的哈。

下面说一下如何安装，APR。其实官网上关于如何安装已经说的很明确了。

Linux依赖：

* APR 1.2+ development headers (libapr1-dev package)
* OpenSSL 0.9.7+ development headers (libssl-dev package)
* JNI headers from Java compatible JDK 1.4+
* GNU development environment (gcc, make)

> The wrapper library sources are located in the Tomcat binary bundle, in the bin/tomcat-native.tar.gz archive. Once the build environment is installed and the source archive is extracted, the wrapper library can be compiled using (from the folder containing the configure script):		
	
	./configure && make && make install

上面是APR的安装。

下面说一下APR的配置，首先在bin/catalina.sh下 JAVA_OPTS处增加

	-Djava.library.path=/usr/local/apr/lib //将APR安装处的lib目录写上
		
然后在，conf/server.xml 的Connector上配置

	protocol="org.apache.coyote.http11.Http11AprProtocol" 

配置好之后再启动Tocmat会出现如下信息。

> Apr 18, 2014 3:25:28 PM org.apache.catalina.core.AprLifecycleListener init
INFO: Loaded APR based Apache Tomcat Native library 1.1.29 using APR version 1.5.0.
.......

> Apr 18, 2014 3:25:28 PM org.apache.coyote.AbstractProtocol init
INFO: Initializing ProtocolHandler ["http-apr-8080"]

> Apr 18, 2014 3:25:29 PM org.apache.coyote.AbstractProtocol init
INFO: Initializing ProtocolHandler ["ajp-apr-8009"]

> Apr 18, 2014 3:25:29 PM org.apache.catalina.startup.Catalina load
INFO: Initialization processed in 960 ms
Apr 18, 2014 3:25:29 PM org.apache.catalina.mbeans.JmxRemoteLifecycleListener createServer

好了，经过我们的调试和优化，使得，单个tomcat承受住了100并发的压力。我们办公地点的网络利用率也在90%以上，并且出现了少数的超时，但整体的成功率在99%以上。还算说得过去。

下面我们开始进行双机的压测

####nginx的负载均衡和动静分离
***
想要双机压测，那必须得有一个负载均衡，我们采用了nginx（其实是使用的淘宝开源的Tengine，但它是在nginx的基础上的）

[Tengine的官网](http://tengine.taobao.org/)

官网上有源码下载，有安装教程，我们此处不再复述。

#####nginx的负载均衡配置
	vi /usr/local/nginx/conf/nginx.conf

找到 在http{下面加入要负载的服务器地址

	upstream web {
        server 192.168.1.100:8080;
        server 192.168.1.101:8080;
        session_sticky; //nginx可以通过ip_hash实现客户端的请求总是分发到同一个服务器
    }

	//在
	server{ //内加入

	location / {
             proxy_pass http://web;
             proxy_set_header  X-Real-IP  $remote_addr;
             client_max_body_size  100m;
        }
这样一来假设我们的tengine是安装在192.168.1.200上的我们就可以通过访问http://192.168.1.200/web来实现负载。

#####静态资源的分离
所谓静态资源就是指，Application中的css、图片、js、html等静态文件。

我们需要告诉nginx那些东西是通过nginx自身提供的，那些是需要转发到被负载的服务器上的。

配置如下：

	location ~* /dwr/? { //URL以dwr开头的需要/web来处理，也就是转发到tomcat上
             proxy_pass http://web;
             proxy_set_header  X-Real-IP  $remote_addr;
             client_max_body_size  100m;
        }

	//下面的这些类型的资源，需要nginx提供，直接去nginx的html目录下访问就行了。
    location ~* ^.+\.(ico|gif|jpg|jpeg|png|html|htm)$ {
                root         html;
                access_log   off;
        }

    location ~* ^.+\.(css|js|txt|xml|swf|wav)$ {
                root         html;
                access_log   off;
        }

我们把静态资源这部分的压力转移到了nginx上，这样会降低tomcat的压力。

#####nginx上的高并发（摘自博客）

一般来说nginx配置文件中对优化比较有作用的为以下几项：

1 nginx进程数，建议按照cpu数目来指定，一般为它的倍数。

	worker_processes 8;
	
	worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000
	01000000 10000000;
	为每个进程分配 cpu，上例中将 8 个进程分配到 8 个 cpu，当然可以写多个，或者将一
	个进程分配到多个cpu。
	worker_rlimit_nofile 102400;
	这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文
	件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit
	-n的值保持一致。
	use epoll;
	使用epoll的I/O模型，这个不用说了吧。
	worker_connections 102400;
	每个进程允许的最多连接数，理论上每台 nginx 服务器的最大连接数为
	worker_processes*worker_connections。
	keepalive_timeout 60;
	keepalive超时时间。
	client_header_buffer_size 4k;
	客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求
	头的大小不会超过 1k，不过由于一般系统分页都要大于 1k，所以这里设置为分页大小。分
	页大小可以用命令getconf PAGESIZE取得。
	open_file_cache max=102400 inactive=20s;
	这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件
	数一致，inactive 是指经过多长时间文件没被请求后删除缓存。
	open_file_cache_valid 30s;
	这个是指多长时间检查一次缓存的有效信息。
	open_file_cache_min_uses 1;
	open_file_cache指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文
	件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，
	它将被移除。

2 关于内核参数的优化： 

	net.ipv4.tcp_max_tw_buckets = 6000
	timewait的数量，默认是180000。
	net.ipv4.ip_local_port_range = 1024 65000
	允许系统打开的端口范围。
	net.ipv4.tcp_tw_recycle = 1
	启用timewait快速回收。
	net.ipv4.tcp_tw_reuse = 1
	开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接。
	net.ipv4.tcp_syncookies = 1
	开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies来处理。
	net.core.somaxconn = 262144
	web 应用中 listen 函数的 backlog 默认会给我们内核参数的 net.core.somaxconn 限制到
	128，而nginx定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。
	net.core.netdev_max_backlog = 262144
	每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包
	的最大数目。
	net.ipv4.tcp_max_orphans = 262144
	系统中最多有多少个TCP套接字不被关联到任何一个用户文件句柄上。如果超过这个数
	字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS攻击，
	不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。
	net.ipv4.tcp_max_syn_backlog = 262144
	记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而
	言，缺省值是1024，小内存的系统则是128。
	net.ipv4.tcp_timestamps = 0
	时间戳可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间
	戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。
	net.ipv4.tcp_synack_retries = 1
	为了打开对端的连接，内核需要发送一个SYN并附带一个回应前面一个SYN的ACK。也
	就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送 SYN+ACK 包的
	数量。
	net.ipv4.tcp_syn_retries = 1
	在内核放弃建立连接之前发送SYN 包的数量。
	net.ipv4.tcp_fin_timeout = 1
	如果套接字由本端要求关闭，这个参数决定了它保持在 FIN-WAIT-2 状态的时间。对端
	可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒。

经过我们队nginx的调试好优化，我们在双机的压测上实现了400并发。这时网络延时的情况已经非常显著了，继续增加并发数也没有多大意义了。

下一步我们准备在内网环境中进行一下真正意义上的极限压测。

敬请期待......